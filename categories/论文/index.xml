<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>论文 on mannuan</title>
    <link>https://mannuan.github.io/categories/%E8%AE%BA%E6%96%87/</link>
    <description>Recent content in 论文 on mannuan</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 22 Jul 2019 09:07:49 +0800</lastBuildDate>
    
	<atom:link href="https://mannuan.github.io/categories/%E8%AE%BA%E6%96%87/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A Large Self-Annotated Corpus for Sarcasm</title>
      <link>https://mannuan.github.io/post/20190722090749/</link>
      <pubDate>Mon, 22 Jul 2019 09:07:49 +0800</pubDate>
      
      <guid>https://mannuan.github.io/post/20190722090749/</guid>
      <description>摘要 该语料库有130万条讽刺性陈述 - 比之前的数据集多10倍 - 并且比非讽刺陈述的例子多几倍，允许在平衡和不平衡的标签系统中学习。每个语句都是自我注释的 - 具有讽刺意味的是作者，而不是独立的注释者 - 并提供用户，主题和对话上下文。
介绍 讽刺检测在数据集中的例子很少、人类难以辨别和现有的数据集平衡的数据标签（数据标签大致相同）这些原因，所以检测讽刺很难。
我们提供了一个用于具有不平衡和自注释标签的讽刺检测的语料库。因为Reddit的评论结构以及经常使用和标准化的讽刺注释。有超过100万个讽刺的例子，每个例子都提供了作者，主题和上下文信息。
我们在第3节讨论了语料库结构和相关统计数据，在第4节手动评估我们语料库的噪声，第5节，我们为讽刺检测系统构建合适的基准，并检查这些子集上的简单基线方法和人类评估者的表现。
相关工作 由于我们的主要贡献是语料库而不是讽刺检测方法。
反讽数据集会有很大的区别，由于获取讽刺或非讽刺陈述的来源，手工标注的数量，和数据集平衡与否。Wallace et al.(2015) 等人使用不平衡的标签，它们不利用自我注释的标签并生成了大约10000各个手工标注的句子。推特的数据集也被用的很多，由于#sarcasm, #notsarcasm和#irony等主题提供了自注释。4.2节提到的，Twitter的缩写语言和其他属性使其变得不那么吸引人。虽然，Twitter是目前最大的原始数据来源并且之前都致力于不平衡的语料库。另外一个评论来源是IAC,这个语料库可以进一步通过人类或机器学习注释为讽刺，大概有产生了10000个带标签的陈述。
语料库细节 Reddit数据集的结构和注释 reddit是一个社交媒体网站，用户通过帖子中的评论进行交流，每一个评论包含了嵌入式媒体，外部链接，和文字，这些发布在指定主题模块的帖子被称为subredddits;这些subreddits包含了搞笑，图片，科学。用户对提交和其他评论进行评论，从而产生了类似树的会话结构。我们把reddit树中的任何节点称为元素（即提交或评论）
reddit用户采用了常用的讽刺注释方法，在讽刺语句的末尾标记&amp;rsquo;/s&amp;rsquo;;这个标记来源于&amp;lt;sarcasm&amp;gt;&amp;lt;/sarcasm&amp;gt;。和Twitter主题标签一样，使用这些标记作为讽刺的指标是嘈杂的，特别是很多用户不使用标记，不知道是不是讽刺，仅仅在讽刺意图不明显的地方使用它，我们在4.1节讨论这种噪音的程度。
构造SARC 我们使用网络爬虫抓取数据，去除了噪音数据。对于每个评论，我们提供一个讽刺标签，作者，subreddit, 用户投票的评论分数，评论的日期，以及回到原始数据集所有评论的标识符。
为了减少噪音，我们使用多个滤镜来消除噪音和无信息的评论。其中许多是标准的预处理步骤，例如排除URL和字符限制在ASCII中。为了处理Reddit数据，我们还排除了作为对话树中的讽刺评论后代的评论，因为在这种表达下，注释非常嘈杂，没有标记作者是否同意先前自己的讽刺表达的讽刺与否。
我们的原始语料库包含了三个文件： 1. 一种CSV格式的数组，包含5.33亿条评论，其中约130万条是讽刺性的。此文件仅包含作者了解标准讽刺注释的注释；这取决于他们是否在评论发布的同一个月或之前使用过注释。添加此限制是为了减少由于作者为注释其讽刺而导致的漏报。每行还包含父注释。 2. 第二个是json格式的哈希表，包含讽刺评论的对话线程中的所有评论和帖子以及所有讽刺评论的兄弟姐妹。 3. csv格式的数组，每行包含一系列导致讽刺的评论，对该序列中的最后一个元素进行(讽刺和非讽刺)的响应。每个元素都作为前一个文件的键。
这种原始语料库非常大，适用于大规模机器学习和统计分析，以及用于评估讽刺检测系统的较小基准任务。这些基准，无论是在平衡还是不平衡的情况下，都需要对语料库进行进一步的子采样，以及在稀疏信号面前处理噪声数据的方法。我们在5.1节评估了这样的方法，然后在输出上评估学习算法。
语料库评估 评估我们的语料库有三个主要的衡量指标：（1）规模，（2）讽刺与非讽刺评论的比例，以及（3）误报率和漏报率。令人感兴趣的还有语料库中的文本质量以及其对其他NLP任务的适用性。因此，在本节中，我们评估原始语料库中的错误，并提供与用于构建讽刺数据集的其他语料库的比较。我们还讨论了我们方法的潜在局限性。
手动评估 为了研究使用Reddit作为自我注释讽刺来源的嘈杂，我们估计了由我们的过滤引起的假阳性和假阴性的比例。 这是通过手动检查来自SARC标记为讽刺和500标记为非讽刺的500条评论的随机子集来完成的，并且可以完全访问评论的上下文。 如果“/ s”标签不是注释而是句子的一部分，并且如果评论作者明显对人类评估者讽刺，则评论被确定为误报。 该程序产生1.0％的假阳性率和2.0％的假阴性率。 虽然假阳性率是合理的，但假讽率与讽刺比例（0.25％）相比是显着的，表明讽刺的工作定义存在很大差异，并且需要能够处理不平衡设置中的噪声数据的方法。 在平衡设置中，这仍然是相当少量的噪音。
与其他数据源进行比较 如前所述，Twitter在以前的语料库中是最常见的讽刺来源; 这可能是由于其主题标签提供的显式注释。 然而，使用Reddit作为讽刺评论的来源具有许多研究优势。 与不受长度约束且包含较少主题标签的Reddit注释不同，推文是用缩写英语编写的。 Hashtagged标记也经常被用作语句本身的一部分（例如“那是#sarcasm”），模糊了文本和注释之间的界限; 在Reddit上，“/ s”通常仅在用作注释时用作注释以外的其他东西（例如“你忘了/ s”）。 由于单个帖子的浅树结构及其注释，Reddit上的完整对话上下文也更容易提供。
此外，从2014年7月的Twitter和Reddit数据的子样本中，我们确定Twitter作者中使用讽刺注释（＃sarcasm，＃sarcastic或#sarcastictweet）的百分比（.002％对.927％）要小得多。 我们假设Reddit用户需要更频繁地以更标准化的形式进行讽刺注释，因为它们主要是匿名的，因此不能依赖共享的上下文来传达讽刺。 最后，Reddit还受益于subreddits，它可以基于明确的主题分配实现特征化和数据探索。
Internet Argument Corpus（IAC）也被用作讽刺评论的来源（Walker等，2012）。 语料库开发人员发现IAC中有12％的例子是讽刺性的，这对于讽刺检测来说比我们的更好。 由于Reddit数据由任意对话组成，而不仅仅是参数，因此即使考虑到假阴性，我们的讽刺百分比也要小得多也就不足为奇了; 此属性还使我们的数据集更加真实。 与Reddit和Twitter不同，IAC还需要手动注释讽刺。
我们方法的局限性 我们收集自注释讽刺数据集的方法有一些值得注意的局限性。 尽管我们努力过滤嘈杂的“/s”标签，但仍存在没有简单规则可靠地消除不正确标签的情况。 我们描述了误报和漏报的困难： * 误报是由于存在“/ s”标记而将评论错误地标记为讽刺的情况。 这种情况仅在评论中出现“/ s”标签时出现，其含义与指示讽刺有所不同。 如前所述，如果用户不知道“/ s”符号，则更有可能发生这种可能性。 类似地，如果“/ s”用于指代其用作注释的约定，那么仅仅检测“/ s”字符串的简单方法也会失败。 最后，“/ s”可能还有其他含义：例如，在HTML中，&amp;lt;s&amp;gt; .</description>
    </item>
    
    <item>
      <title>反讽论文的研究反向</title>
      <link>https://mannuan.github.io/post/20190722084636/</link>
      <pubDate>Mon, 22 Jul 2019 08:46:36 +0800</pubDate>
      
      <guid>https://mannuan.github.io/post/20190722084636/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CASCADE: Contextual Sarcasm Detection in Online Discussion Forums翻译和解读</title>
      <link>https://mannuan.github.io/post/20190717110201/</link>
      <pubDate>Wed, 17 Jul 2019 11:02:01 +0800</pubDate>
      
      <guid>https://mannuan.github.io/post/20190717110201/</guid>
      <description>摘要  The literature in automated sarcasm detection has mainly focused on lexical-, syntactic- and semantic-level analysis of text. However, a sarcastic sentence can be expressed with contextual presumptions, background and commonsense knowledge. In this paper, we propose a ContextuAl SarCasm DEtector (CASCADE), which adopts a hybrid approach of both content- and context-driven modeling for sarcasm detection in online social media discussions. For the latter, CASCADE aims at extracting contextual information from the discourse of a discussion thread.</description>
    </item>
    
    <item>
      <title>Latex常用设置</title>
      <link>https://mannuan.github.io/post/20190709170202/</link>
      <pubDate>Tue, 09 Jul 2019 17:02:02 +0800</pubDate>
      
      <guid>https://mannuan.github.io/post/20190709170202/</guid>
      <description>bib文件点击跳转 在.tex文件开头加上\usepackage[backref]{hyperref}。</description>
    </item>
    
    <item>
      <title>Representing Social Media Users for Sarcasm Detection论文翻译和解读</title>
      <link>https://mannuan.github.io/post/20190704162010/</link>
      <pubDate>Thu, 04 Jul 2019 16:20:10 +0800</pubDate>
      
      <guid>https://mannuan.github.io/post/20190704162010/</guid>
      <description>Representing Social Media Users for Sarcasm Detection  用于讽刺检测的社交媒体用户的特征表示
 摘要 在上下文讽刺检测的背景下，两种表示作者特征的方式：
 使用贝叶斯的方式直接表示作者的讽刺倾向；
 密集向量嵌入可以学习到作者和文本之间的交互；
 使用reddit评论的SARC数据集，双向的rnn可以提高性能；
  贝叶斯的方法在同质的上下文中是足够的，密集的向量嵌入是有价值的 the Bayesian approach suffices in homogeneous contexts, whereas the added power of the dense embeddings proves valuable in more diverse ones. 
  介绍  Irony and sarcasm1 are extreme examples of context-dependence in language. Given only the text Great idea! or What a hardship!, we cannot resolve the speaker’s intentions unless we have in- sight into the circumstances of utterance – who is speaking, and to whom, and how the content relates to the preceding discourse (Clark, 1996).</description>
    </item>
    
  </channel>
</rss>